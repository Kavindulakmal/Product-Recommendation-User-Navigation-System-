# -*- coding: utf-8 -*-
"""Product recommendation-content based filtering.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BMYJVz0pOWsT5u7-2kE0SOrEgK9LDnf-

Content-based filtering is a type of recommender system that attempts to guess what a user may like based on that user's activity. Content-based filtering makes recommendations by using keywords and attributes assigned to objects in a database (e.g., items in an online marketplace) and matching them to a user profile.
"""

import pandas as pd

"""# Loading Dataset"""

from google.colab import drive
drive.mount('/content/drive')

df = pd.read_csv('/content/drive/MyDrive/product_recommendation_dataset/dataset.csv')

df.head()

"""# EDA"""

df.info()

df.shape

"""Dataset has two columns and 500 data rows"""

df.describe()

df['description'][0]

"""Contains html elements that needed to be cleaned

# Preprocessing

### Remove HTML Elements
"""

import re


def remove_html_elements(text):
    return re.sub(r"<[a-z/]+>", " ", text) 

# example execution
print(remove_html_elements(df['description'][0]))

df['description'] = df['description'].apply(lambda x: remove_html_elements(x))

"""### Remove special characters"""

def remove_special_char(text):
    return re.sub(r"[^A-Za-z]+", " ", text)

# example execution
print(remove_special_char(df['description'][0]))

df['description'] = df['description'].apply(lambda x: remove_special_char(x))

"""### Remove multiple spaces"""

def remove_whitespaces(text):
    return re.sub(' +', ' ', text)
    
# example execution to see the effect
print(remove_whitespaces(df['description'][0]))

df['description'] = df['description'].apply(lambda x: remove_whitespaces(x))

"""### Make all lowercase"""

df['description'] = df['description'].apply(lambda x: x.lower())
# example execution to see the effect
print(df['description'][0])

"""# Content Based Filtering

TfidfVectorizer is the base building block of many NLP pipelines. It is a simple technique to vectorize text documents — i.e. transform sentences into arrays of numbers — and use them in subsequent tasks.

Linear Kernel is used when the data is Linearly separable, that is, it can be separated using a single Line. It is one of the most common kernels to be used. It is mostly used when there are a Large number of Features in a particular Data Set.
"""

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import linear_kernel

t_vec = TfidfVectorizer(
    analyzer='word',
    ngram_range=(1, 3),
    min_df=0,
    stop_words='english')

tvec_matrix = t_vec.fit_transform(df['description'])

tvec_matrix

"""**cosine similarity**

Cosine similarity measures the similarity between two vectors of an inner product space.
"""

cosine_similarities = linear_kernel(tvec_matrix, tvec_matrix)

results = {}

for idx, row in df.iterrows():
    print('{} {}'.format(idx, row))
    similar_indices = cosine_similarities[idx].argsort()[:-100:-1]
    similar_items = [(cosine_similarities[idx][i], df['id'][i]) for i in similar_indices]

    # remove first item, because it's a copy
    results[row['id']] = similar_items[1:]

results
# { id : [(similarity, id)], ...}

"""# Get Predictions"""

# retrieve item description
def get_item(id):
    description = df.loc[df['id'] == id]['description'].tolist()[0]
    return description

get_item(1)

# get n number of similar product ids from cosine similarity results
def get_recommendations(item_id, num_of_rec=3):
    # get n number of records (n = num_of_rec)
    recs = results[item_id][:num_of_rec]
    for idx, rec in enumerate(recs):
        print('Recommendation {}: {}\nScore: {}'.format(idx, get_item(rec[1]), rec[0]))
        print('---------------------------------------------------------------------')

get_recommendations(1, 3)

